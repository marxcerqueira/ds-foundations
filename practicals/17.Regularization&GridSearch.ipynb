{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Learning Objectives\n",
    "\n",
    "We firm up what regularization is and when to use it. And we show how a computer can pick the optimal amount of regularization through grid search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regularization\n",
    "\n",
    "As we saw regularization was one of the tools that we had to fight the bias variance tradeoff. But we did not see how to effectively use it. We saw that it was able to, with fine grain precision, determine the size of our hypothesis set. We of course know that the size of the hypothesis set is crucial to the final out of sample performance. \n",
    "\n",
    "But how do we determine what is the best size for the hypothesis set?\n",
    "\n",
    "We can determine this using by iterating over a set of regularization parameters and then determining which had the best results. An important note here is that we will be evaluating the final performance on a validation set and this will be able to tell us which hypothesis will do best on outside data. \n",
    "\n",
    "Let's go ahead and try this with our decision tree to see if we can get better out of sample performance: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "breast_cancer_data = load_breast_cancer()\n",
    "\n",
    "# we make our test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(breast_cancer_data['data'], breast_cancer_data['target'], test_size=0.2, random_state=1)\n",
    "\n",
    "# and we make our validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "cls = DecisionTreeClassifier(max_depth=5, min_samples_leaf=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Notice that I show two ways to regularize my decision tree (there are more). And notice that these fit quite nicely into the paradigm of reducing the hypothesis set. Instead we would be looking at trees with a max depth of five or looking where their leaves can only be so small.\n",
    "\n",
    "This is perhaps even easier to understand than weight penalization (the most common form of regularization), where you would add to the loss function the sum of the absolute values or squares of the weights.\n",
    "\n",
    "So what we would do is iterate over different regularization strengths and choose the one that did best on the validation set. Let's show how you would do this below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max depth 2\n",
      "min samples leaf 5\n",
      "error 0.90873015873\n",
      "max depth 2\n",
      "min samples leaf 10\n",
      "error 0.90873015873\n",
      "max depth 2\n",
      "min samples leaf 20\n",
      "error 0.925683060109\n",
      "max depth 4\n",
      "min samples leaf 5\n",
      "error 0.952455590387\n",
      "max depth 4\n",
      "min samples leaf 10\n",
      "error 0.90873015873\n",
      "max depth 4\n",
      "min samples leaf 20\n",
      "error 0.925683060109\n",
      "max depth 6\n",
      "min samples leaf 5\n",
      "error 0.952455590387\n",
      "max depth 6\n",
      "min samples leaf 10\n",
      "error 0.90873015873\n",
      "max depth 6\n",
      "min samples leaf 20\n",
      "error 0.925683060109\n",
      "max depth 8\n",
      "min samples leaf 5\n",
      "error 0.952455590387\n",
      "max depth 8\n",
      "min samples leaf 10\n",
      "error 0.90873015873\n",
      "max depth 8\n",
      "min samples leaf 20\n",
      "error 0.925683060109\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# here is where we do grid search\n",
    "for max_depth in range(2, 10, 2):\n",
    "    for min_samples_leaf in [5, 10, 20]:\n",
    "        cls = DecisionTreeClassifier(max_depth=max_depth, min_samples_leaf=min_samples_leaf)\n",
    "        cls.fit(X_train, y_train)\n",
    "        \n",
    "        error = roc_auc_score(cls.predict(X_val), y_val)\n",
    "        \n",
    "        print('max depth {}'.format(max_depth))\n",
    "        print('min samples leaf {}'.format(min_samples_leaf))\n",
    "        print('error {}'.format(error))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Notice that we achieve the best out of sample error somewhere in the middle, where the regularization is not highest, but is high enough.\n",
    "\n",
    "Of course we should be concerned if we are doing this too much. We don't want to run too too many experiments. If we run too many the errors that we get on the validation set may not be reflective or reality. But the above has shown us that we can get great performance just by changing the hyperparameter (those not learned) of the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## In summary\n",
    "\n",
    "Regularization is a way to automatically control the size of the hypothesis set, and we can use a computer in order to find the best regularization needed. Generally speaking the models in sklearn will come with docstrings that explain the way to regularize them. \n",
    "\n",
    "Regularization may sometimes be confused with inductive bias (which we will talk about a bit later on)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Learning Objectives\n",
    "\n",
    "We firm up what regularization is and when to use it. And we show how a computer can pick the optimal amount of regularization through grid search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Comprehension Questions\n",
    "\n",
    "1.\tHow do we know what the best regularization is?\n",
    "2.\tWhy is putting a penalty on large weights regularization?\n",
    "3.\tIs changing models a type of regularization?\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
