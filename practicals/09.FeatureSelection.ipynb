{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Learning Objectives\n",
    "\n",
    "Today we will learn about two types of feature selection: variance thresholding and univariate feature selection and put them both into practice on a real dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Feature selection\n",
    "\n",
    "So you know that you want to do supervised learning. You have already gathered relevant summary statistics on the data and visualized it. You have transformed your quantitative features, imputed or dropped NaNs, and standardized those that are quantitative. Now you are interested in what features you will want to include in the final prediction task. This part of machine learning is called feature selection. Again we are going to cover a couple of practical methods of doing feature selection while explaining the intuition behind them. Let's start off by repeating all of the process that we did above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('../data/billionaires.csv')\n",
    "\n",
    "del df['was founder']\n",
    "del df['inherited']\n",
    "del df['from emerging']\n",
    "\n",
    "df.age.replace(-1, np.NaN, inplace=True)\n",
    "df.founded.replace(0, np.NaN, inplace=True)\n",
    "df.gdp.replace(0, np.NaN, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# first we delete some features that we won't use in prediction\n",
    "data = df.copy()\n",
    "del data['company.name']\n",
    "del data['name']\n",
    "del data['country code']\n",
    "del data['citizenship']\n",
    "del data['rank']\n",
    "del data['relationship']\n",
    "del data['sector']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>category</th>\n",
       "      <th>company.type</th>\n",
       "      <th>founded</th>\n",
       "      <th>gdp</th>\n",
       "      <th>gender</th>\n",
       "      <th>industry</th>\n",
       "      <th>region</th>\n",
       "      <th>was political</th>\n",
       "      <th>wealth.type</th>\n",
       "      <th>worth in billions</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Financial</td>\n",
       "      <td>new</td>\n",
       "      <td>1968.0</td>\n",
       "      <td>1.580000e+11</td>\n",
       "      <td>male</td>\n",
       "      <td>Money Management</td>\n",
       "      <td>Middle East/North Africa</td>\n",
       "      <td>False</td>\n",
       "      <td>self-made finance</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34.0</td>\n",
       "      <td>Financial</td>\n",
       "      <td>new</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>8.100000e+12</td>\n",
       "      <td>female</td>\n",
       "      <td>Money Management</td>\n",
       "      <td>North America</td>\n",
       "      <td>False</td>\n",
       "      <td>inherited</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59.0</td>\n",
       "      <td>Non-Traded Sectors</td>\n",
       "      <td>new</td>\n",
       "      <td>1948.0</td>\n",
       "      <td>8.540000e+11</td>\n",
       "      <td>male</td>\n",
       "      <td>Retail, Restaurant</td>\n",
       "      <td>Latin America</td>\n",
       "      <td>False</td>\n",
       "      <td>inherited</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61.0</td>\n",
       "      <td>New Sectors</td>\n",
       "      <td>new</td>\n",
       "      <td>1881.0</td>\n",
       "      <td>2.500000e+12</td>\n",
       "      <td>male</td>\n",
       "      <td>Technology-Medical</td>\n",
       "      <td>Europe</td>\n",
       "      <td>False</td>\n",
       "      <td>inherited</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Financial</td>\n",
       "      <td>new</td>\n",
       "      <td>1816.0</td>\n",
       "      <td>1.600000e+11</td>\n",
       "      <td>male</td>\n",
       "      <td>Money Management</td>\n",
       "      <td>East Asia</td>\n",
       "      <td>False</td>\n",
       "      <td>inherited</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age            category company.type  founded           gdp  gender  \\\n",
       "0   NaN           Financial          new   1968.0  1.580000e+11    male   \n",
       "1  34.0           Financial          new   1946.0  8.100000e+12  female   \n",
       "2  59.0  Non-Traded Sectors          new   1948.0  8.540000e+11    male   \n",
       "3  61.0         New Sectors          new   1881.0  2.500000e+12    male   \n",
       "4   NaN           Financial          new   1816.0  1.600000e+11    male   \n",
       "\n",
       "             industry                    region  was political  \\\n",
       "0    Money Management  Middle East/North Africa          False   \n",
       "1    Money Management             North America          False   \n",
       "2  Retail, Restaurant             Latin America          False   \n",
       "3  Technology-Medical                    Europe          False   \n",
       "4    Money Management                 East Asia          False   \n",
       "\n",
       "         wealth.type  worth in billions  year  \n",
       "0  self-made finance                1.0  1996  \n",
       "1          inherited                2.5  1996  \n",
       "2          inherited                1.2  1996  \n",
       "3          inherited                1.0  1996  \n",
       "4          inherited                2.2  1996  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# next we will make the qualitative columns into dummies\n",
    "dummy_data = pd.get_dummies(data, dummy_na=True, columns=data.select_dtypes(exclude=['float64']), drop_first=True)\n",
    "\n",
    "len(dummy_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2614, 3)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "y = dummy_data['worth in billions']\n",
    "del dummy_data['worth in billions']\n",
    "\n",
    "qualitative_features = dummy_data.select_dtypes(exclude=['float64'])\n",
    "quantitative_features = dummy_data.select_dtypes(include=['float64'])\n",
    "\n",
    "# first we imput nan values\n",
    "imp = Imputer(strategy='median')\n",
    "quant_X = imp.fit_transform(quantitative_features)\n",
    "\n",
    "# and now we scale the data that is quantitative\n",
    "std_scaler = StandardScaler()\n",
    "quant_X = std_scaler.fit_transform(quant_X)\n",
    "\n",
    "quant_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Two strategies\n",
    "\n",
    "We will be going over two strategies here, both simple ways to reduce the total number of features in your model (in the next few classes we will be going over some non obvious reasons why you might want to do this - for now you can think of this as dropping useless data). The two strategies are:\n",
    "\n",
    "1. Variance thresholding\n",
    "2. Univariate feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Variance thresholding\n",
    "\n",
    "This is a simple strategy that removes features of low variance from the model. This makes a large implicit assumption that features of low variance will not be as predictive. I'll show you how to use it below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2614, 70)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.concatenate([quant_X, qualitative_features], axis=1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2614, 17)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# we start off with 71 columns\n",
    "vt = VarianceThreshold(threshold=0.1)\n",
    "X_vt = vt.fit_transform(X)\n",
    "\n",
    "# we end with 17\n",
    "X_vt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2614, 67)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it can often be good to threshold at 0.0 just to remove obviously redundent data\n",
    "vt = VarianceThreshold(threshold=0.0)\n",
    "X = vt.fit_transform(X)\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Univariate feature selection\n",
    "\n",
    "The next best thing we can do is to select features based on a scoring funciton. The scoring function will try to do its best to tell us how relevant the features are, but realize this has shortcomings. First without seeing all the features and how they work together it is hard to tell which will be the best ones. Thus this becomes a combinatorial problem in the extreme. And second each model has different assumptions, and thus require different scoring functions. \n",
    "\n",
    "That being said let's go ahead and pick out the 'best' 15 features from our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2614, 15)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "# we select mutual informaiton regression in because \n",
    "# we are initially interested in worth in billions, a quantitative feature\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "skb = SelectKBest(mutual_info_regression, k=15)\n",
    "\n",
    "# notice that this also needs to know the y variable\n",
    "X = skb.fit_transform(X, y)\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'founded', u'gdp', u'company.type_ new', u'company.type_new',\n",
       "       u'company.type_subsidiary', u'industry_Consumer',\n",
       "       u'industry_Diversified financial', u'industry_Energy',\n",
       "       u'industry_Non-consumer industrial', u'industry_Real Estate',\n",
       "       u'industry_Technology-Computer', u'industry_nan',\n",
       "       u'region_North America', u'wealth.type_privatized and resources',\n",
       "       u'wealth.type_self-made finance'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can use the get_support function in order to see the columns that we took:\n",
    "dummy_data.columns[vt.get_support()][skb.get_support()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1% finished\n",
    "\n",
    "This is certainly not the end. There are many more strategies and if you want a more comprehensive take on them check out: [here](https://www.youtube.com/watch?v=wjKvyk8xStg&list=PLgJhDSE2ZLxb33q-x5592LCiVRsHDxVf3&index=6). (One of my favorites is recursive feature selection). \n",
    "\n",
    "But even more so, we are just about to begin our journey into supervised learning. So get ready!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Learning Objectives\n",
    "\n",
    "Today we will learn about two types of feature selection: variance thresholding and univariate feature selection and put them both into practice on a real dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Comprehension Questions\n",
    "\n",
    "1.\tWhy don’t we use all the features? Why do we only select some?\n",
    "2.\tHow can we tell what a good feature is?\n",
    "3.\tWould you want to standardize before or after variance thresholding?\n",
    "4.\tWhy can’t we do multivariate feature selection?\n",
    "5.\tHow do you know how many features to select with univariate feature selection?\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
