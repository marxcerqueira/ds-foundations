{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The end\n",
    "\n",
    "We have gone over the major theoretical points of supervised machine learning through the lens of computer science and bootstrap sampling, and I think now it seems like a good time to talk about what could be said is the most important part, the inductive bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "But before that let's go over what we have done:\n",
    "\n",
    "1. We have looked at what data is (qualitative and quantitative data)\n",
    "2. We have talked about summary statistics of this data\n",
    "3. We have shown that we can use bootstrap sampling to infer summary statistics of population data from a sample\n",
    "4. We have defined supervised learning\n",
    "5. We have used bootstrap sampling to show that we can learn in a one or multiple hypothesis setting\n",
    "6. We have learned the approximation generalization trade off\n",
    "7. We have learned the bias variance trade off\n",
    "8. We have learned why we have those trade offs with deterministic and stochastic noise\n",
    "9. We have learned how to use regularization, cross validation and bagging in order to fight those trade offs and have a more effective model\n",
    "\n",
    "Wow, we have done a lot, but the most important lesson is yet to come."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Machine Learning (as opposed to AI) is a methodology of induction. We see examples and seek to make a rule. That being said there is one big step that is not inductive in ML, and that is choosing the hypothesis set.\n",
    "\n",
    "The choice of the hypothesis set is the most important part and to be done by a seasoned practitioner. In fact most of ML research that goes on today is about this very problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The hypothesis set\n",
    "\n",
    "Why is it so important? Well we learned that choosing a good size for the hypothesis set is generally important, but we also learned that we can use validation and regularization in order to 'algorithmically' choose an appropriate size. So then what gives? \n",
    "\n",
    "Well let's give an example:\n",
    "\n",
    "Suppose we are trying to model the locations of dark matter in the universe. We could use an incredibly general model that has to learn EVERYTHING from the ground up including gravity! Or we could build all of that knowledge into the system and have it learn something smaller and more tractable with the amount of data that we have. \n",
    "\n",
    "In this example you can see how picking the right inductive bias is very important. \n",
    "\n",
    "But for most applications it is more subtle but equally important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## NLP\n",
    "\n",
    "A specific example of inductive bias selection is in NLP. It used to be that people would spend years imposing their own grammers and understanding of how language works in order to do the supervised task of translation. But now people only provide a sequence of characters to an ML algorithm and it works better! \n",
    "\n",
    "This is a cautionary tale of picking the right inductive bias. Sometimes you can beleive that you have a full understanding of how something works but when it comes time to put your ML where your mouth is you lose out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Other algorithms\n",
    "\n",
    "One thing that you may hve found conspicuously missing from this course is other algorithms. We learned a single commonly used algorithm this entire course: Linear Regression. Where are the SVMs and Random Forests and Neural Networks?\n",
    "\n",
    "Well while each of these are important on their own, I think they should instead be the subject of another course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
